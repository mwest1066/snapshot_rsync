#!/usr/bin/env python
#
# snapshot_rsync
#
# Copyright 2004-2010 Matthew West
#
# This work is licensed under a Creative Commons Attribution 3.0
# United States License:
# http://creativecommons.org/licenses/by/3.0/us/

import sys, getopt, datetime, re, os, string, time, subprocess

######################################################################
# Global defines.

# Version number of this script
version_string = '0.1.0'

# printf-like format to generate ISO 8601 dates
isodate_format = '%04d-%02d-%02dT%02d:%02d:%02d%+03d:%02d'

# Regular expression to match an ISO 8601 date. 8 fields are:
#   year, month, day, hour, minute, second, timezone_hour, timezone_minute
isodate_re = '(\d\d\d\d)-(\d\d)-(\d\d)T(\d\d):(\d\d):(\d\d)([+-]\d\d):(\d\d)$'

######################################################################
# Global variables that can be over-ridden by command-line arguments.

# Source directory to be backed up.
src = ""

# Destination directory to make the backup in.
dst = ""

# List of 2-tuples of the form (past, delta) which mean that the
# minimum time spacing between backups is <delta> between the
# current time and (current_time - <past>). Both <past> and <delta>
# are timedelta objects. The requirements of the list <delete_req>
# are the union of the individual requirements.
delete_req = []

# Whether to print diagnostic information while running (True or False).
print_diags = False

# Whether to delete old backups before making the new one (True or False).
delete_first = False

# Name of the rsync binary to use (should be an absolute pathname).
rsync_bin = '/usr/bin/rsync'

# Whether to run in safe-mode (True or False), where no external
# commands will be executed, and no filesystem modifications
# performed. Instead a message will be printed for each operation,
# specifying what it would have been.
safe_mode = False

# Whether to use SSH to access the source directory. If so, the name
# of the remote machine.
ssh_machine = False

######################################################################
######################################################################
######################################################################

def print_usage():
	print """snapshot_rsync: Make a backup snapshot of a given directory.

Usage: snapshot_rsync [options] <src> <dst>
  <src>      the source directory to backup.
  <dst>      the directory in which to make the backup.

Options:
  -d                Delete old backups before making the new backup. This
  --delete-first    ensures minimum space usage but can lead to inefficient
                    transfers and risks having fewer backups temporarily.
                    The default is to delete after the new backup is done.

  -k <n>,<m>        Delete old backups, keeping at least one backup every m
  --keep <n>,<m>    days between now and n days ago. Multiple -k arguments
                    stack so that all constraints are satisfied. All backups
                    older than the largest <n> are deleted. Backups are only
                    deleted if at least one -k argument is provided.

  -h, --help        Print this usage help.

  --rsync <name>    Set the name of the rsync binary to use.

  --safe-mode       Do not actually execute any commands or delete anything,
                    but print what would have been done.

  -s <name>         Use rsync over SSH to the remote machine <name> to
  --ssh <name>      access <src>.

  -v, --verbose     Print extra diagnostic information while running.

  -V, --version     Print the version number.

Example: snapshot_rsync -k 7,1 -k 360,30 /home/user1 /backups

This will create a backup of /home/user1 of the form
/backups/user1.<isodate>, with hard links made where possible to the
most recent pre-existing backup with the same form of name. All old
backups will be deleted, except for enough to ensure that we retain at
least one backup per day for the last week, and at least one backup
per month for the last year."""

######################################################################

def print_version():
	print "snapshot_rsync " + version_string

######################################################################
# Get a list of existing backups in <backup_dir> which have a name of
# the form <prefix>.<isodate>.
#
# Returns a list of 2-tuples of the form (backup_time, backup_name),
# sorted by age with most recent first. The backup_time has no
# timezone and is UTC.

def get_old_backups(backup_dir, prefix):
	try:
		dir_list = os.listdir(backup_dir)
	except OSError, inst:
		print "Error reading directory " + backup_dir + ": " + str(inst)
		sys.exit(1)
	old_backups = []
	n = len(prefix)
	for dir_entry in dir_list:
		if dir_entry[:n] != prefix:
			continue
		if len(dir_entry) < n + 2:
			continue
		if dir_entry[n] != '.':
			continue
		dir_time = string_to_time(dir_entry[(n+1):])
		if not dir_time:
			continue
		old_backups.append((dir_time, dir_entry))
	old_backups.sort()
	if print_diags:
		if len(old_backups) > 0:
			print "Found old backups:"
			for backup_time, backup_name in old_backups:
				print '  ' + backup_name + ' at time ' + backup_time.isoformat('T') + 'Z'
		else:
			print "Did not find any old backups"
	return old_backups

######################################################################
# Process the commandline and change any global variables necessary.
#
# Does not return anything.

def process_cmdline():
	global src
	global dst
	global delete_req
	global print_diags
	global delete_first
	global rsync_bin
	global safe_mode
	global ssh_machine
	try:
		options, args = getopt.gnu_getopt(sys.argv[1:], 'k:hdvVs:', ['help', 'version', 'keep=', 'verbose', 'delete-first', 'safe-mode', 'ssh='])
	except getopt.GetoptError, inst:
		print "Error processing command line: " + str(inst)
		print "Run 'snapshot_rsync -h' for help"
		sys.exit(2)
	for opt, opt_val in options:
		if opt in ('-h', '--help'):
			print_usage()
			sys.exit()
		if opt in ('-V', '--version'):
			print_version()
			sys.exit()
		if opt in ('-k', '--keep'):
			match = re.compile('^(\d+),(\d+)$').search(opt_val)
			if match == None:
				print "Error processing argument -d " + opt_val
				print "Run 'snapshot_rsync -h' for help"
				sys.exit(2)
			days_past = int(match.group(1))
			days_delta = int(match.group(2))
			delete_req.append((datetime.timedelta(days = days_past),
				datetime.timedelta(days = days_delta)))
		if opt in ('-v', '--verbose'):
			print_diags = True
		if opt in ('-d', '--delete-first'):
			delete_first = True
		if opt == '--rsync':
			rsync_bin = opt_val
		if opt == '--safe-mode':
			safe_mode = True
		if opt in ('-s', '--ssh'):
			ssh_machine = opt_val
	if len(args) != 2:
		print "Must provide exactly two non-option commandline arguments."
		print "Run 'snapshot_rsync -h' for help"
		sys.exit(2)
	src = args[0]
	dst = args[1]
	#src = os.path.normpath(os.path.abspath(args[0]))
	#dst = os.path.normpath(os.path.abspath(args[1]))
	if print_diags:
		print "Processed command line:"
		print "  Using source: " + src
		print "  Using dest: " + dst
		if len(delete_req) > 0:
			for a in delete_req:
				past, delta = a
				print "  Keep one backup every " + str(delta) + " for the past " + str(past)
		else:
			print "  No deletions to be done"

######################################################################
# Parses a string in ISO 8601 format and returns a datetime object
# for the UTC equivalent of the time in the string. That is, the
# returned datetime will not have a timezone set.

def string_to_time(time_string):
	date_re = re.compile(isodate_re)
	match = date_re.search(time_string)
	if not match:
		return None
	year = int(match.group(1))
	month = int(match.group(2))
	day = int(match.group(3))
	hour = int(match.group(4))
	minute = int(match.group(5))
	second = int(match.group(6))
	tz_hour = int(match.group(7))
	tz_minute = int(match.group(8))
	ret_time = datetime.datetime(year, month, day, hour, minute, second)
	tz_offset = datetime.timedelta(hours = tz_hour, minutes = tz_minute)
	ret_time = ret_time - tz_offset
	return ret_time

######################################################################
# Computes a set of backups to delete given the list of current
# backups in <old_backups> and the requirements <delete_req> to
# be satisfied by the remaining set after deletion.
#
# The current backup will never be deleted, and all backups newer than
# the current one will be deleted (it is assumed that they are failed
# backups).
#
# <old_backups> must be in the form returned by get_old_backups() and
# must include any backups that were just performed.
#
# <delete_req> must be in the form of the global variable <delete_req>
#
# If <delete_req> is an empty list then no deletions are performed.
#
# Returns a list of strings which are the basenames of the backups
# that should be deleted.
#
# The algorithm used is just a simple greedy one, starting at the
# most-recent-but-one backup, after stripping off backups past the
# oldest requirement date.

def get_backups_to_delete(old_backups, current_name, delete_req):
        # only do this if we have some keep requirements
        if len(delete_req) == 0:
                return []

	usable_old_backups = old_backups
	backups_to_delete = []

        # strip off all backups newer than current
        if current_name:
                new_usable_old_backups = []
                current_time = string_to_time(current_name)
                for backup in usable_old_backups:
                        cur_time, cur_name = backup
                        if cur_time <= current_time:
                                new_usable_old_backups.append(backup)
                        else:
                                backups_to_delete.append(cur_name)
                usable_old_backups = new_usable_old_backups

	# strip off backups that are too old
        new_usable_old_backups = []
	largest_past = max([datetime.timedelta(days = 0)] \
			   + [past for past, delta in delete_req])
	now_time = datetime.datetime.utcnow()
	for backup in usable_old_backups:
		cur_time, cur_name = backup
		if now_time - cur_time < largest_past:
			new_usable_old_backups.append(backup)
		else:
			backups_to_delete.append(cur_name)
        usable_old_backups = new_usable_old_backups

	# greedy algorithm to find backup set that satisfies requirements
	if len(usable_old_backups) < 2:
		return backups_to_delete
	prev_i = len(usable_old_backups) - 1
	for i in range(len(usable_old_backups) - 2, 0, -1):
		cur_time, cur_name = usable_old_backups[i]
		prev_time, prev_name = usable_old_backups[prev_i]
		found_restriction = False
		for restriction in delete_req:
			past, delta = restriction
			if now_time - prev_time < past:
				if not found_restriction:
					found_restriction = True
					min_restriction = delta
				else:
					if delta < min_restriction:
						min_restriction = delta
		if not found_restriction:
			backups_to_delete.append(cur_name)
			continue
		if i == 0:
			continue
		post_time, post_name = usable_old_backups[i-1]
		if prev_time - post_time < min_restriction:
			backups_to_delete.append(cur_name)
			continue
		prev_i = i
	return backups_to_delete

######################################################################
# Recursively deletes the given directory and all of its subdirs.

def rm_tree(dir_name):
	if os.path.isdir(dir_name) and not os.path.islink(dir_name):
		for dir_entry in os.listdir(dir_name):
			rm_tree(os.path.join(dir_name, dir_entry))
		os.rmdir(dir_name)
	else:
		os.unlink(dir_name)

######################################################################
# Delete old backups

def delete_old_backups(src, dst, current_name):
	old_backups = get_old_backups(dst, os.path.basename(src))
	backups_to_delete = get_backups_to_delete(old_backups, current_name, delete_req)
	
	try:
		for dir in backups_to_delete:
			rm_name = os.path.join(dst, dir)
			if print_diags:
				print "Deleting old backup " + rm_name
			if not safe_mode:
				rm_tree(rm_name)
				log(src, dst, "Deleting old backup " + rm_name)
			else:
				print "safe_mode: rm_tree: " + rm_name
	except Exception, inst:
		print "Error deleting " + dir + ": " + str(inst)
		sys.exit(5)

######################################################################
# Logging

def log(src, dst, msg):
	logfilename = os.path.join(dst, "log.%s" % os.path.basename(src))
	try:
                if print_diags:
                        print msg
		logfile = open(logfilename, "a")
		logfile.write("%s snapshot_rsync[%d] %s\n"
			      % (datetime.datetime.now().isoformat(),
				 os.getpid(), msg))
		logfile.close()
	except:
		print "Error writing to logfile " + logfilename
		sys.exit(4)
	
######################################################################
######################################################################
######################################################################
# Main program

process_cmdline()

log(src, dst, "Started backup from %s to %s" % (src, dst))

# Lock file
lock_filename = os.path.join(dst, "lock.%s" % os.path.basename(src))
try:
	# try to open the lock file exclusively (fails if it already exists)
	lock = os.open(lock_filename,
		       os.O_EXCL | os.O_CREAT | os.O_WRONLY, 0644)
except:
        # failed to open the lock exclusively, try to steal it
        log(src, dst, "Lock file exists, trying to steal it")
        try:
                lock = open(lock_filename)
                lock_info = lock.readline()
                lock.close()
        except Exception as inst:
                log(src, dst, "Error aquiring lock: %s: %s" % (type(inst), str(inst)))
                sys.exit(4)
        try:
                match = re.search('^PID (\d+) at (.+)$', lock_info)
                if not match:
                        print "Error parsing existing lock file info: " + lock_filename
                        log(src, dst, "Error parsing old lock " + lock_filename + ": exiting" )
                        sys.exit(3)
                old_pid = int(match.group(1))
                old_time = match.group(2)
                # could use this and get the output to check it is us
                #ps_cmd = ["ps", "-o", "comm=", "-p", str(old_pid)]
                # but for now we just check if PID exists at all
                ps_cmd = ["ps", "-p", str(old_pid)]
                log(src, dst, "Old lock was for PID %d at time %s" % (old_pid, old_time))
                if print_diags:
                        print "Running command: " + " ".join(ps_cmd)
                ps_process = subprocess.Popen(ps_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                (stdoutdata, stdindata) = ps_process.communicate()
                ps_result = ps_process.returncode
                if print_diags:
                        print "ps returned %d" % ps_result
                if ps_result == 0:
                        # ps was successful, command with PID exists
                        log(src, dst, "Failed to aquire lock " + lock_filename
                            + " (old process still running): exiting" )
                        sys.exit(3)
                if ps_result != 1:
                        # random ps error
                        log(src, dst, "Error running ps to check existing process: %d" % ps_result)
                        sys.exit(3)
                # ps_result == 1, so there was no such process with PID
                # steal the lock
                log(src, dst, "Old process no longer exists, stealing lock")
                lock = os.open(lock_filename,
                               os.O_CREAT | os.O_WRONLY | os.O_TRUNC, 0644)
        except Exception as inst:
                log(src, dst, "Error aquiring lock: %s: %s" % (type(inst), str(inst)))
                sys.exit(4)
# store our own PID in the lock file
try:
	os.write(lock, "PID %d at %s\n"
		 % (os.getpid(), datetime.datetime.now().isoformat()))
	os.close(lock)
except Exception as inst:
	log(src, dst, "Error writing PID to lock file: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished lock aquire")

# Find the symlink that points to the most recent successful backup.
current_link_filename = os.path.join(dst, "current.%s" % os.path.basename(src))
link_dest = None
link_dest_arg = ''
if print_diags:
        print "current link filename: %s" % current_link_filename
try:
        if os.path.exists(current_link_filename):
                if not os.path.islink(current_link_filename):
                        raise Exception("Current link is not a symlink: "
                                        + current_link_filename)
                link_dest = os.readlink(current_link_filename)
                if print_diags:
                        print "current link points to: %s" % link_dest
                list_dest_arg = '--link-dest=' + link_dest
except Exception as inst:
	log(src, dst, "Error determining link_dest: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
if print_diags:
        print "link_dest argument: " + link_dest_arg
log(src, dst, "Finished determining link_dest")

# Delete old backups first if necessary
try:
	if delete_first:
		delete_old_backups(src, dst, link_dest)
except Exception as inst:
	log(src, dst, "Error deleting old backups first: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished deleting old backups first")

# Compute the name of new backup (of the form <src>.<isodate>)
try:
	curtime = time.localtime()
	backup_name = os.path.basename(src) + '.' + isodate_format % ( \
		curtime.tm_year, curtime.tm_mon, curtime.tm_mday, \
		curtime.tm_hour, curtime.tm_min, curtime.tm_sec, \
		(-time.timezone) / 3600, ((-time.timezone) / 60) % 60)
except Exception as inst:
	log(src, dst, "Error determining backup_name: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished determining backup_name")

# Compute the commandline for rsync
try:
	rsync_args = ['-a']
	if len(link_dest_arg) > 0:
		rsync_args.append(link_dest_arg)
	if ssh_machine:
		rsync_src = ssh_machine + ':' + src
	else:
		rsync_src = src
	rsync_args.extend([rsync_src, os.path.join(dst, backup_name)])

	if ssh_machine:
		rsync_args = ['--rsh=ssh'] + rsync_args

	rsync_cmd = [rsync_bin] + rsync_args

	if print_diags:
		print "rsync command to run: " + string.join(rsync_cmd)
except Exception as inst:
	log(src, dst, "Error computing rsync_cmd: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished computing rsync_cmd")

# Call rsync
try:
	if not safe_mode:
		ret = os.spawnv(os.P_WAIT, rsync_bin, rsync_cmd)
		if ret < 0:
			print "Error: rsync terminated by signal " + str(-ret)
			sys.exit(1)
		if ret > 0:
			print "Error: rsync terminated with error " + str(ret)
			sys.exit(1)
	else:
		print "safe_mode: run command: " + string.join(rsync_cmd)
except Exception as inst:
	log(src, dst, "Error running rsync: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished running rsync")

# Make the symlink to the just completed backup.
try:
        if not safe_mode:
                new_link_filename = current_link_filename + ".new"
                if print_diags:
                        print "new_link_filename: " + new_link_filename
                if os.path.exists(new_link_filename):
                        print "new_link_filename already exists, unlinking it"
                        os.unlink(new_link_filename)
                if print_diags:
                        print "symlinking %s -> %s" % (new_link_filename, backup_name)
                os.symlink(backup_name, new_link_filename)
                if print_diags:
                        print "renaming %s -> %s" % (new_link_filename, current_link_filename)
                os.rename(new_link_filename, current_link_filename)
        else:
                print "safe_mode: symlink %s -> %s" % (current_link_filename, backup_name)
except Exception as inst:
	log(src, dst, "Error making current symlink: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished making current symlink")

# Delete any unnecessary old backups
try:
	if not delete_first:
		delete_old_backups(src, dst, backup_name)
except Exception as inst:
	log(src, dst, "Error deleting old backups last: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished deleting old backups last")

# Remove lock file
try:
	os.unlink(lock_filename)
except Exception as inst:
	log(src, dst, "Error releasing lock: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished releasing lock")

log(src, dst, "Backup completed successfully")

######################################################################
######################################################################
######################################################################
