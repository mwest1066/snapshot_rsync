#!/usr/bin/env python
#
# snapshot_rsync
#
# Copyright 2004-2010 Matthew West
#
# This work is licensed under a Creative Commons Attribution 3.0
# United States License:
# http://creativecommons.org/licenses/by/3.0/us/

import sys, getopt, datetime, re, os, string, time

######################################################################
# Global defines.

# Version number of this script
version_string = '0.1.0'

# printf-like format to generate ISO 8601 dates
isodate_format = '%04d-%02d-%02dT%02d:%02d:%02d%+03d:%02d'

# Regular expression to match an ISO 8601 date. 8 fields are:
#   year, month, day, hour, minute, second, timezone_hour, timezone_minute
isodate_re = '^(\d\d\d\d)-(\d\d)-(\d\d)T(\d\d):(\d\d):(\d\d)([+-]\d\d):(\d\d)$'

######################################################################
# Global variables that can be over-ridden by command-line arguments.

# Source directory to be backed up.
src = ""

# Destination directory to make the backup in.
dst = ""

# List of 2-tuples of the form (past, delta) which mean that the
# minimum time spacing between backups is <delta> between the
# current time and (current_time - <past>). Both <past> and <delta>
# are timedelta objects. The requirements of the list <delete_req>
# are the union of the individual requirements.
delete_req = []

# Whether to print diagnostic information while running (True or False).
print_diags = False

# Whether to delete old backups before making the new one (True or False).
delete_first = False

# Name of the rsync binary to use (should be an absolute pathname).
rsync_bin = '/usr/bin/rsync'

# Whether to run in safe-mode (True or False), where no external
# commands will be executed, and no filesystem modifications
# performed. Instead a message will be printed for each operation,
# specifying what it would have been.
safe_mode = False

# Whether to use SSH to access the source directory. If so, the name
# of the remote machine.
ssh_machine = False

######################################################################
######################################################################
######################################################################

def print_usage():
	print """snapshot_rsync: Make a backup snapshot of a given directory.

Usage: snapshot_rsync [options] <src> <dst>
  <src>      the source directory to backup.
  <dst>      the directory in which to make the backup.

Options:
  -d                Delete old backups before making the new backup. This
  --delete-first    ensures minimum space usage but can lead to inefficient
                    transfers and risks having fewer backups temporarily.
		    The default is to delete after the new backup is done.

  -k <n>,<m>        Delete old backups, keeping at least one backup every m
  --keep <n>,<m>    days between now and n days ago. Multiple -k arguments
                    stack so that all constraints are satisfied. All backups
		    older than the largest <n> are deleted.

  -h, --help        Print this usage help.

  --rsync <name>    Set the name of the rsync binary to use.

  --safe-mode       Do not actually execute any commands or delete anything,
                    but print what would have been done.

  -s <name>         Use rsync over SSH to the remote machine <name> to
  --ssh <name>      access <src>.

  -v, --verbose     Print extra diagnostic information while running.

  -V, --version     Print the version number.

Example: snapshot_rsync -k 7,1 -k 360,30 /home/user1 /backups

This will create a backup of /home/user1 of the form
/backups/user1.<isodate>, with hard links made where possible to the
most recent pre-existing backup with the same form of name. All old
backups will be deleted, except for enough to ensure that we retain at
least one backup per day for the last week, and at least one backup
per month for the last year."""

######################################################################

def print_version():
	print "snapshot_rsync " + version_string

######################################################################
# Get a list of existing backups in <backup_dir> which have a name of
# the form <prefix>.<isodate>.
#
# Returns a list of 2-tuples of the form (backup_time, backup_name),
# sorted by age with most recent first. The backup_time has no
# timezone and is UTC.

def get_old_backups(backup_dir, prefix):
	try:
		dir_list = os.listdir(backup_dir)
	except OSError, inst:
		print "Error reading directory " + backup_dir + ": " + str(inst)
		sys.exit(1)
	old_backups = []
	n = len(prefix)
	for dir_entry in dir_list:
		if dir_entry[:n] != prefix:
			continue
		if len(dir_entry) < n + 2:
			continue
		if dir_entry[n] != '.':
			continue
		dir_time = string_to_time(dir_entry[(n+1):])
		if not dir_time:
			continue
		old_backups.append((dir_time, dir_entry))
	old_backups.sort()
	if print_diags:
		if len(old_backups) > 0:
			print "Found old backups:"
			for backup_time, backup_name in old_backups:
				print '  ' + backup_name + ' at time ' + backup_time.isoformat('T') + 'Z'
		else:
			print "Did not find any old backups"
	return old_backups

######################################################################
# Process the commandline and change any global variables necessary.
#
# Does not return anything.

def process_cmdline():
	global src
	global dst
	global delete_req
	global print_diags
	global delete_first
	global rsync_bin
	global safe_mode
	global ssh_machine
	try:
		options, args = getopt.gnu_getopt(sys.argv[1:], 'k:hdvVs:', ['help', 'version', 'keep=', 'verbose', 'delete-first', 'safe-mode', 'ssh='])
	except getopt.GetoptError, inst:
		print "Error processing command line: " + str(inst)
		print "Run 'snapshot_rsync -h' for help"
		sys.exit(2)
	for opt, opt_val in options:
		if opt in ('-h', '--help'):
			print_usage()
			sys.exit()
		if opt in ('-V', '--version'):
			print_version()
			sys.exit()
		if opt in ('-k', '--keep'):
			match = re.compile('^(\d+),(\d+)$').search(opt_val)
			if match == None:
				print "Error processing argument -k " + opt_val
				print "Run 'snapshot_rsync -h' for help"
				sys.exit(2)
			days_past = int(match.group(1))
			days_delta = int(match.group(2))
			delete_req.append((datetime.timedelta(days = days_past),
				datetime.timedelta(days = days_delta)))
		if opt in ('-v', '--verbose'):
			print_diags = True
		if opt in ('-d', '--delete-first'):
			delete_first = True
		if opt == '--rsync':
			rsync_bin = opt_val
		if opt == '--safe-mode':
			safe_mode = True
		if opt in ('-s', '--ssh'):
			ssh_machine = opt_val
	if len(args) != 2:
		print "Must provide exactly two non-option commandline arguments."
		print "Run 'snapshot_rsync -h' for help"
		sys.exit(2)
	src = args[0]
	dst = args[1]
	#src = os.path.normpath(os.path.abspath(args[0]))
	#dst = os.path.normpath(os.path.abspath(args[1]))
	if print_diags:
		print "Processed command line:"
		print "  Using source: " + src
		print "  Using dest: " + dst
		if len(delete_req) > 0:
			for a in delete_req:
				past, delta = a
				print "  Keep one backup every " + str(delta) + " for the past " + str(past)
		else:
			print "  No deletions to be done"

######################################################################
# Parses a string in ISO 8601 format and returns a datetime object
# for the UTC equivalent of the time in the string. That is, the
# returned datetime will not have a timezone set.

def string_to_time(time_string):
	date_re = re.compile(isodate_re)
	match = date_re.search(time_string)
	if not match:
		return None
	year = int(match.group(1))
	month = int(match.group(2))
	day = int(match.group(3))
	hour = int(match.group(4))
	minute = int(match.group(5))
	second = int(match.group(6))
	tz_hour = int(match.group(7))
	tz_minute = int(match.group(8))
	ret_time = datetime.datetime(year, month, day, hour, minute, second)
	tz_offset = datetime.timedelta(hours = tz_hour, minutes = tz_minute)
	ret_time = ret_time - tz_offset
	return ret_time

######################################################################
# Computes a set of backups to delete given the list of current
# backups in <old_backups> and the requirements <delete_req> to
# be satisfied by the remaining set after deletion.
#
# <old_backups> must be in the form returned by get_old_backups() and
# must include any backups that were just performed.
#
# <delete_req> must be in the form of the global variable <delete_req>
#
# Returns a list of strings which are the basenames of the backups
# that should be deleted.
#
# The algorithm used is just a simple greedy one, starting at the
# most-recent-but-one backup, after stripping off backups past the
# oldest requirement date.

def get_backups_to_delete(old_backups, delete_req):
	# strip off backups that are too old
	usable_old_backups = []
	backups_to_delete = []
	largest_past = max([datetime.timedelta(days = 0)] \
			   + [past for past, delta in delete_req])
	now_time = datetime.datetime.utcnow()
	for backup in old_backups:
		cur_time, cur_name = backup
		if now_time - cur_time < largest_past:
			usable_old_backups.append(backup)
		else:
			backups_to_delete.append(cur_name)

	# greedy algorithm to find backup set that satisfies requirements
	if len(usable_old_backups) < 2:
		return backups_to_delete
	prev_i = len(usable_old_backups) - 1
	for i in range(len(usable_old_backups) - 2, 0, -1):
		cur_time, cur_name = usable_old_backups[i]
		prev_time, prev_name = usable_old_backups[prev_i]
		found_restriction = False
		for restriction in delete_req:
			past, delta = restriction
			if now_time - prev_time < past:
				if not found_restriction:
					found_restriction = True
					min_restriction = delta
				else:
					if delta < min_restriction:
						min_restriction = delta
		if not found_restriction:
			backups_to_delete.append(cur_name)
			continue
		if i == 0:
			continue
		post_time, post_name = usable_old_backups[i-1]
		if prev_time - post_time < min_restriction:
			backups_to_delete.append(cur_name)
			continue
		prev_i = i
	return backups_to_delete

######################################################################
# Recursively deletes the given directory and all of its subdirs.

def rm_tree(dir_name):
	if os.path.isdir(dir_name) and not os.path.islink(dir_name):
		for dir_entry in os.listdir(dir_name):
			rm_tree(os.path.join(dir_name, dir_entry))
		os.rmdir(dir_name)
	else:
		os.unlink(dir_name)

######################################################################
# Delete old backups

def delete_old_backups(src, dst):
	old_backups = get_old_backups(dst, os.path.basename(src))
	backups_to_delete = get_backups_to_delete(old_backups, delete_req)
	
	try:
		for dir in backups_to_delete:
			rm_name = os.path.join(dst, dir)
			if print_diags:
				print "Deleting old backup " + rm_name
			if not safe_mode:
				rm_tree(rm_name)
				log(src, dst, "Deleting old backup " + rm_name)
			else:
				print "safe_mode: rm_tree: " + rm_name
	except Exception, inst:
		print "Error deleting " + dir + ": " + str(inst)
		sys.exit(5)

######################################################################
# Logging

def log(src, dst, msg):
	logfilename = os.path.join(dst, "log.%s" % os.path.basename(src))
	try:
		logfile = open(logfilename, "a")
		logfile.write("%s snapshot_rsync[%d] %s\n"
			      % (datetime.datetime.now().isoformat(),
				 os.getpid(), msg))
		logfile.close()
	except:
		print "Error writing to logfile " + logfilename
		sys.exit(4)
	
######################################################################
######################################################################
######################################################################
# Main program

process_cmdline()

log(src, dst, "Started backup from %s to %s" % (src, dst))

# Lock file
lock_filename = os.path.join(dst, "lock.%s" % os.path.basename(src))
try:
	# try to open the lock file exclusively (fails if it already exists)
	lock = os.open(lock_filename,
		       os.O_EXCL | os.O_CREAT | os.O_WRONLY, 0644)
except:
	# If we can't acquire the lock, we don't attempt to check
	# whether the locking process is still running and steal the
	# lock, because that will hide backup failures. If the old
	# backup process died and didn't release the lock correctly,
	# we probably want to manually delete the failed backup as
	# well, so that we don't hardlink against a partial backup.
	print "Error aquiring lock file " + lock_filename
	log(src, dst, "Failed to aquire lock " + lock_filename + ": exiting" )
	sys.exit(3)
# store our own PID in the lock file
try:
	os.write(lock, "PID %d at %s"
		 % (os.getpid(), datetime.datetime.now().isoformat()))
	os.close(lock)
except Exception as inst:
	log(src, dst, "Error writing PID to lock file: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished lock aquire")

# Delete old backups first if necessary
try:
	if delete_first:
		delete_old_backups(src, dst)
except Exception as inst:
	log(src, dst, "Error deleting old backups first: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished deleting old backups first")

# If we have any pre-existing backups, use the most recent as the
# link-dest argument to rsync.
try:
	old_backups = get_old_backups(dst, os.path.basename(src))
	if len(old_backups) > 0:
		previous_time, previous_backup = old_backups[-1]
		link_dest_arg = '--link-dest=' + os.path.join(dst, previous_backup)
	else:
		link_dest_arg = ''
except Exception as inst:
	log(src, dst, "Error determining link_dest: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished determining link_dest")

# Compute the name of new backup (of the form <src>.<isodate>)
try:
	curtime = time.localtime()
        if time.daylight != 0:
                tz = time.altzone
        else:
                tz = time.timezone
	backup_name = os.path.basename(src) + '.' + isodate_format % ( \
		curtime.tm_year, curtime.tm_mon, curtime.tm_mday, \
		curtime.tm_hour, curtime.tm_min, curtime.tm_sec, \
		(-tz) / 3600, ((-tz) / 60) % 60)
except Exception as inst:
	log(src, dst, "Error determining backup_name: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished determining backup_name")

# Compute the commandline for rsync
try:
	rsync_args = ['-a']
	if len(link_dest_arg) > 0:
		rsync_args.append(link_dest_arg)
	if ssh_machine:
		rsync_src = ssh_machine + ':' + src
	else:
		rsync_src = src
	rsync_args.extend([rsync_src, os.path.join(dst, backup_name)])

	if ssh_machine:
		rsync_args = ['--rsh=ssh'] + rsync_args

	rsync_cmd = [rsync_bin] + rsync_args

	if print_diags:
		print "rsync command to run: " + string.join(rsync_cmd)
except Exception as inst:
	log(src, dst, "Error computing rsync_cmd: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished computing rsync_cmd")

# Call rsync
try:
	if not safe_mode:
		ret = os.spawnv(os.P_WAIT, rsync_bin, rsync_cmd)
		if ret < 0:
			print "Error: rsync terminated by signal " + str(-ret)
			sys.exit(1)
		if ret > 0:
			print "Error: rsync terminated with error " + str(ret)
			sys.exit(1)
	else:
		print "safe_mode: run command: " + string.join(rsync_cmd)
except Exception as inst:
	log(src, dst, "Error running rsync: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished running rsync")

# Delete any unnecessary old backups
try:
	if not delete_first:
		delete_old_backups(src, dst)
except Exception as inst:
	log(src, dst, "Error deleting old backups last: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished deleting old backups last")

# Remove lock file
try:
	os.unlink(lock_filename)
except Exception as inst:
	log(src, dst, "Error releasing lock: %s: %s" % (type(inst), str(inst)))
	sys.exit(4)
log(src, dst, "Finished releasing lock")

log(src, dst, "Backup completed successfully")

######################################################################
######################################################################
######################################################################
